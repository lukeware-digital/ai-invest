# üöÄ Como Fazer o CeciAI Funcionar

**Objetivo:** Instalar o que precisa e fazer a aplica√ß√£o rodar  
**Tempo:** 10 minutos

---

## üì¶ O Que Voc√™ Precisa

### Obrigat√≥rio:
- ‚úÖ **Python 3.11+** - [Baixar aqui](https://www.python.org/downloads/)
- ‚úÖ **Ollama** - LLM gratuito - [Baixar aqui](https://ollama.com/download)
- ‚úÖ **8 GB RAM** 
- ‚úÖ **5 GB espa√ßo disco**

### Opcional:
- üê≥ Docker (se quiser usar containers)

---

## üöÄ Como Fazer Rodar (Passo a Passo)

### 1Ô∏è‚É£ Baixar o C√≥digo

```bash
git clone https://github.com/lukeware-digital/ai-invest.git
cd ai-invest
```

### 2Ô∏è‚É£ Instalar Python (se n√£o tiver)

```bash
# Verificar se tem Python
python3 --version

# Deve mostrar: Python 3.11.x ou superior
```

**N√£o tem Python?** Baixe em: https://www.python.org/downloads/

### 3Ô∏è‚É£ Criar Ambiente Virtual

```bash
# Linux/Mac
python3 -m venv .venv
source .venv/bin/activate

# Windows (PowerShell)
python -m venv .venv
.venv\Scripts\Activate.ps1

# Windows (CMD)
python -m venv .venv
.venv\Scripts\activate.bat
```

‚úÖ **Sucesso:** Deve aparecer `(.venv)` no in√≠cio da linha do terminal

### 4Ô∏è‚É£ Instalar Bibliotecas Python

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

‚è±Ô∏è **Aguarde:** ~3-5 minutos baixando bibliotecas

### 5Ô∏è‚É£ Instalar Ollama (IA Local)

**Linux:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

**Mac:**
```bash
brew install ollama
# Ou baixar de: https://ollama.com/download
```

**Windows:**
- Baixe: https://ollama.com/download
- Execute o instalador
- Pronto! (inicia automaticamente)

### 6Ô∏è‚É£ Baixar Modelo de IA

```bash
# Baixar modelo (2GB)
ollama pull llama3.2:3b

# Verificar se baixou
ollama list
```

‚úÖ **Deve mostrar:** `llama3.2:3b` na lista

### 7Ô∏è‚É£ Iniciar Ollama

```bash
# Linux/Mac (em segundo plano)
ollama serve &

# Windows - j√° est√° rodando automaticamente

# Verificar se est√° rodando
curl http://localhost:11434
```

### 8Ô∏è‚É£ Criar Dados de Exemplo

```bash
# Criar diret√≥rios necess√°rios
mkdir -p data/historical

# Criar dados de teste
python -c "
import pandas as pd
from datetime import datetime, timedelta

dates = pd.date_range(end=datetime.now(), periods=100, freq='1H')
df = pd.DataFrame({
    'timestamp': dates,
    'open': [50000 + i*10 for i in range(100)],
    'high': [51000 + i*10 for i in range(100)],
    'low': [49000 + i*10 for i in range(100)],
    'close': [50500 + i*10 for i in range(100)],
    'volume': [1000000 + i*1000 for i in range(100)]
})
df.to_parquet('data/historical/BTC_USD_1h.parquet')
print('‚úÖ Dados criados!')
"
```

---

## ‚ñ∂Ô∏è Como Rodar a Aplica√ß√£o

### Op√ß√£o A: Apenas API (Mais Simples)

```bash
# Ativar ambiente virtual (se n√£o estiver ativado)
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# Rodar API
uvicorn api.main:app --host 0.0.0.0 --port 8000
```

‚úÖ **Funcionou?** Acesse: http://localhost:8000/docs

### Op√ß√£o B: API + Dashboard Visual

**Terminal 1 - API:**
```bash
source .venv/bin/activate
uvicorn api.main:app --host 0.0.0.0 --port 8000
```

**Terminal 2 - Dashboard:**
```bash
source .venv/bin/activate
streamlit run dashboard.py --server.port 8050
```

‚úÖ **Acessos:**
- API: http://localhost:8000/docs
- Dashboard: http://localhost:8050

---

## üß™ Como Testar se Funcionou

### Teste 1: API est√° respondendo?

```bash
curl http://localhost:8000/health
```

‚úÖ **Deve retornar:** `{"status":"healthy",...}`

### Teste 2: Fazer uma an√°lise

```bash
curl -X POST "http://localhost:8000/api/v1/analyze-candles" \
  -H "Content-Type: application/json" \
  -d '{
    "symbol": "BTC/USD",
    "candles": [
      {"timestamp": "2025-10-08T10:00:00Z", "open": 50000, "high": 50200, "low": 49900, "close": 50100, "volume": 1000000},
      {"timestamp": "2025-10-08T11:00:00Z", "open": 50100, "high": 50300, "low": 50000, "close": 50200, "volume": 1100000},
      {"timestamp": "2025-10-08T12:00:00Z", "open": 50200, "high": 50400, "low": 50100, "close": 50300, "volume": 1200000}
    ],
    "capital_available": 10000
  }'
```

‚úÖ **Deve retornar:** An√°lise com decis√£o BUY/SELL/HOLD

### Teste 3: Dashboard funcionando?

Abra no navegador: http://localhost:8050

‚úÖ **Deve mostrar:** Dashboard com gr√°ficos e m√©tricas

---

## üß™ Primeiro Teste

### Teste Completo do Sistema

```bash
# Executar todos os testes
python scripts/test_complete_system.py

# Sa√≠da esperada:
# ‚úÖ PASSOU: Configura√ß√µes
# ‚úÖ PASSOU: Ollama LLM
# ‚úÖ PASSOU: Modelos ML
# ‚úÖ PASSOU: Agentes (9/9)
# ‚úÖ PASSOU: Pipeline Completo
# ‚úÖ PASSOU: API REST
# ‚úÖ PASSOU: Capital Management
# ‚úÖ PASSOU: Backtesting
# üéâ SISTEMA 100% FUNCIONAL!
```

### Teste da API

```bash
# Iniciar API (se n√£o estiver rodando)
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000

# Testar an√°lise de candles
python scripts/test_api_live.py

# Ou usar curl
curl -X POST "http://localhost:8000/api/v1/analyze-candles" \
  -H "Content-Type: application/json" \
  -d '{
    "symbol": "BTC/USD",
    "candles": [
      {"timestamp": "2025-10-08T10:00:00Z", "open": 50000, "high": 50200, "low": 49900, "close": 50100, "volume": 1000000},
      {"timestamp": "2025-10-08T11:00:00Z", "open": 50100, "high": 50300, "low": 50000, "close": 50200, "volume": 1100000}
    ],
    "capital_available": 10000,
    "strategy": "scalping"
  }'
```

---

## üìä Uso B√°sico

### An√°lise Simples

```python
import asyncio
import pandas as pd
from agents.pipeline import AgentPipeline

async def analyze_market():
    # Dados de exemplo (substitua por dados reais)
    data = {
        'timestamp': ['2025-10-08T10:00:00Z', '2025-10-08T11:00:00Z'],
        'open': [50000, 50100],
        'high': [50200, 50300], 
        'low': [49900, 50000],
        'close': [50100, 50200],
        'volume': [1000000, 1100000]
    }
    df = pd.DataFrame(data)
    
    # Executar an√°lise completa
    pipeline = AgentPipeline()
    result = await pipeline.execute(
        df=df,
        symbol='BTC/USD',
        timeframe='1h',
        capital_available=10000.0
    )
    
    # Resultado
    decision = result['final_decision']
    print(f"üéØ Decis√£o: {decision['decision']}")
    print(f"üìä Confian√ßa: {decision['confidence']:.0%}")
    print(f"üí∞ Valor sugerido: ${decision.get('quantity_usd', 0):,.2f}")
    
    if decision['decision'] == 'BUY':
        print(f"üìà Entry: ${decision.get('entry_price', 0):,.2f}")
        print(f"üõë Stop Loss: ${decision.get('stop_loss', 0):,.2f}")
        print(f"üéØ Take Profit: ${decision.get('take_profit_1', 0):,.2f}")

# Executar
asyncio.run(analyze_market())
```

### Backtesting R√°pido

```python
import asyncio
from backtesting.backtest_engine import BacktestEngine
from strategies.scalping import ScalpingStrategy

async def quick_backtest():
    # Carregar dados hist√≥ricos (exemplo)
    df = pd.read_csv('data/historical/BTC_USD_1h.csv')  # Se existir
    
    # Configurar backtest
    backtest = BacktestEngine(initial_capital=10000)
    strategy = ScalpingStrategy()
    
    # Executar
    results = await backtest.run(df, strategy, None)
    
    # M√©tricas principais
    print(f"üí∞ Retorno Total: {results['total_return']:.2%}")
    print(f"üìä Win Rate: {results['metrics']['win_rate']:.2%}")
    print(f"üìà Sharpe Ratio: {results['metrics']['sharpe_ratio']:.2f}")
    print(f"üìâ Max Drawdown: {results['metrics']['max_drawdown']:.2%}")
    print(f"üî¢ Total Trades: {results['metrics']['total_trades']}")

asyncio.run(quick_backtest())
```

---

## üîß Configura√ß√£o

### Vari√°veis de Ambiente (.env)

```bash
# Ollama (LLM)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL_PRIMARY=llama3.2:3b

# Trading
INITIAL_CAPITAL=10000
MAX_DAILY_LOSS=0.03
MAX_POSITION_SIZE=0.20
ENABLE_TRADING=false
USE_PAPER_TRADING=true

# CoinAPI (opcional - para dados reais)
COINAPI_KEY=your-key-here
COINAPI_MODE=development

# Ambiente
CECIAI_ENV=development
LOG_LEVEL=INFO
```

### Personalizar Capital

```python
from config.capital_management import CapitalManager

# Configurar capital inicial
capital_mgr = CapitalManager(
    initial_capital=50000,      # $50k inicial
    max_daily_loss=0.02,        # M√°ximo 2% perda/dia
    max_position_size=0.15,     # M√°ximo 15% por posi√ß√£o
    max_concurrent_positions=3   # M√°ximo 3 posi√ß√µes simult√¢neas
)
```

---

## üêõ Troubleshooting

### ‚ùå Problema: "Docker Compose n√£o encontrado"

**Erro:**
```
‚ùå Docker Compose n√£o encontrado
make: *** [Makefile:63: check-system] Error 1
```

**Solu√ß√£o:** Use a instala√ß√£o sem Docker (Op√ß√£o 1)! √â mais simples e r√°pida.

```bash
# Siga os passos da Op√ß√£o 1 (Sem Docker):
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
# ... continue com os demais passos
```

**Ou instale o Docker** (opcional):
```bash
# Ubuntu/Debian
sudo apt-get update
sudo apt-get install docker.io docker-compose

# Mac
brew install docker docker-compose

# Windows
# Baixar de: https://www.docker.com/products/docker-desktop
```

---

### ‚ùå Problema: Ollama n√£o responde

```bash
# Verificar se est√° rodando
ollama list

# Se n√£o estiver, iniciar
ollama serve

# Ou em background (Linux/Mac)
nohup ollama serve > /dev/null 2>&1 &

# Baixar modelo se necess√°rio
ollama pull llama3.2:3b

# Verificar se modelo foi baixado
ollama list | grep llama3.2
```

---

### ‚ùå Problema: "ModuleNotFoundError"

```bash
# Ativar ambiente virtual
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# Reinstalar depend√™ncias
pip install --upgrade pip
pip install -r requirements.txt

# Verificar instala√ß√£o
pip list | grep -E "(fastapi|streamlit|pandas)"
```

---

### ‚ùå Problema: Erro de GPU / CUDA

```bash
# Verificar CUDA (opcional - sistema funciona sem GPU)
nvidia-smi

# Se n√£o tiver GPU, for√ßar uso de CPU
export CUDA_VISIBLE_DEVICES=""
export OLLAMA_GPU_LAYERS=0

# Reiniciar Ollama
pkill ollama
ollama serve &
```

---

### ‚ùå Problema: API n√£o inicia (porta em uso)

```bash
# Verificar o que est√° usando a porta
lsof -i :8000
# Ou no Windows:
# netstat -ano | findstr :8000

# Matar processo (se necess√°rio)
kill -9 <PID>

# Ou usar porta diferente
uvicorn api.main:app --port 8001
```

---

### ‚ùå Problema: "Sem dados dispon√≠veis"

```bash
# Baixar dados hist√≥ricos
python utils/download_historical_data.py

# Ou criar dados de exemplo
python -c "
import pandas as pd
from datetime import datetime, timedelta

# Criar dados de exemplo
dates = pd.date_range(end=datetime.now(), periods=100, freq='1H')
data = {
    'timestamp': dates,
    'open': 50000,
    'high': 51000,
    'low': 49000,
    'close': 50500,
    'volume': 1000000
}
df = pd.DataFrame(data)
df.to_parquet('data/historical/BTC_USD_1h.parquet')
print('‚úÖ Dados de exemplo criados!')
"
```

---

### ‚ùå Problema: Modelos ML n√£o encontrados

**Isso √© normal!** Os modelos ML s√£o opcionais. O sistema funciona sem eles.

```bash
# Se quiser treinar os modelos (opcional):
python scripts/train_ml_models.py

# Verificar se foram criados
ls -la data/models/

# O sistema usa fallback se modelos n√£o existirem
```

---

### ‚ùå Problema: Permiss√£o negada no Linux

```bash
# Dar permiss√£o para scripts
chmod +x scripts/*.sh
chmod +x scripts/*.py

# Se necess√°rio, usar sudo para Ollama
sudo curl -fsSL https://ollama.com/install.sh | sh
```

---

## üìä Comandos √öteis

```bash
# Sistema
make build          # Build completo
make up             # Iniciar containers
make down           # Parar containers
make logs           # Ver logs
make clean          # Limpar tudo

# Testes
python scripts/test_complete_system.py    # Teste completo
python scripts/test_api_live.py          # Teste API
python scripts/train_ml_models.py        # Treinar ML

# API
uvicorn api.main:app --reload            # Desenvolvimento
uvicorn api.main:app --host 0.0.0.0      # Produ√ß√£o

# Dados
python utils/download_historical_data.py  # Download dados
python utils/data_updater.py             # Atualizar dados
```

---

## ‚úÖ Checklist de Valida√ß√£o

Ap√≥s instala√ß√£o, verificar:

- [ ] `ollama list` mostra llama3.2:3b
- [ ] `python scripts/test_complete_system.py` passa todos os testes
- [ ] `curl http://localhost:8000/health` retorna 200 OK
- [ ] `ls data/models/` mostra modelos ML treinados
- [ ] An√°lise de exemplo executa sem erros

---

## üéØ Pr√≥ximos Passos

1. ‚úÖ **Sistema funcionando** - Parab√©ns!
2. üìñ **Entender arquitetura** - Leia [ARCHITECTURE.md](ARCHITECTURE.md)
3. üß™ **Testar API** - Veja [API_USAGE.md](API_USAGE.md)
4. üöÄ **Deploy produ√ß√£o** - Siga [DEPLOYMENT.md](DEPLOYMENT.md)
5. üí∞ **Paper trading** - Comece com capital virtual
6. üìä **Backtesting** - Teste estrat√©gias com dados hist√≥ricos

---

**üéâ Sistema pronto! Agora voc√™ pode comprar e vender no momento certo!** üöÄüìà

**Tempo total:** ~10 minutos ‚è±Ô∏è